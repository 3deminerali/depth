{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depthExtraction002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c08eeb4f662545a892edf20b3fcb125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_217b19a4c2b343d590dc494b6a092d03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d43798ca4ead475fbd19d60dbf0c03f3",
              "IPY_MODEL_36204d9fcd434e1fad0c5311ec8b1d7f"
            ]
          }
        },
        "217b19a4c2b343d590dc494b6a092d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d43798ca4ead475fbd19d60dbf0c03f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c3848d80c8a4d7396cbbea4d6f9cb88",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 356056638,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 356056638,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c09d580704cb47e29388cdf389b43146"
          }
        },
        "36204d9fcd434e1fad0c5311ec8b1d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e7f01d76af84d8da4427edd96720d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 340M/340M [00:11&lt;00:00, 31.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6be5268c3a841e78b7ac513d75829f8"
          }
        },
        "2c3848d80c8a4d7396cbbea4d6f9cb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c09d580704cb47e29388cdf389b43146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e7f01d76af84d8da4427edd96720d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6be5268c3a841e78b7ac513d75829f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "713d3418dc4740fcad97b99349218917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccdaf98c18d348bbbced890f6429d282",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_745a87fd951b43f2bf73fa47edb8564c",
              "IPY_MODEL_77fe04b7a9054a8db1ae5b6cabaf308a"
            ]
          }
        },
        "ccdaf98c18d348bbbced890f6429d282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "745a87fd951b43f2bf73fa47edb8564c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_929d3fd396964c5592e4fa5259f3217f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 422509849,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 422509849,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5915d29bba54449ad497a3f6ab2c79c"
          }
        },
        "77fe04b7a9054a8db1ae5b6cabaf308a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29cca5a64beb47ff8fe468663fe23e90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 403M/403M [00:04&lt;00:00, 99.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f7ec3e7680045ae9d66efa1ffc42671"
          }
        },
        "929d3fd396964c5592e4fa5259f3217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5915d29bba54449ad497a3f6ab2c79c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29cca5a64beb47ff8fe468663fe23e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f7ec3e7680045ae9d66efa1ffc42671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3deminerali/depth/blob/main/depthExtraction002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9kQ9O7wNjwY"
      },
      "source": [
        "Based on https://pytorch.org/hub/intelisl_midas_v2/ \n",
        "and https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/intelisl_midas_v2.ipynb\n",
        "\n",
        "### Reference\n",
        "[Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341)\n",
        "\n",
        "Please cite paper if you use their model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "AY10PtMwNjwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6ace66a3-77d8-4a45-e4a3-f38e68d9a489"
      },
      "source": [
        "'''@article{Ranftl2020,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\n",
        "\ttitle     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\n",
        "\tjournal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n",
        "\tyear      = {2020},\n",
        "}'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@article{Ranftl2020,\\n\\tauthor    = {Ren'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\\n\\ttitle     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\\n\\tjournal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\\n\\tyear      = {2020},\\n}\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzpbfnmoNjwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "c08eeb4f662545a892edf20b3fcb125b",
            "217b19a4c2b343d590dc494b6a092d03",
            "d43798ca4ead475fbd19d60dbf0c03f3",
            "36204d9fcd434e1fad0c5311ec8b1d7f",
            "2c3848d80c8a4d7396cbbea4d6f9cb88",
            "c09d580704cb47e29388cdf389b43146",
            "6e7f01d76af84d8da4427edd96720d61",
            "f6be5268c3a841e78b7ac513d75829f8",
            "713d3418dc4740fcad97b99349218917",
            "ccdaf98c18d348bbbced890f6429d282",
            "745a87fd951b43f2bf73fa47edb8564c",
            "77fe04b7a9054a8db1ae5b6cabaf308a",
            "929d3fd396964c5592e4fa5259f3217f",
            "a5915d29bba54449ad497a3f6ab2c79c",
            "29cca5a64beb47ff8fe468663fe23e90",
            "6f7ec3e7680045ae9d66efa1ffc42671"
          ]
        },
        "outputId": "e1a53ea4-bd62-4649-83be-187dcc740eb9"
      },
      "source": [
        "#Set runtime to GPU\n",
        "\n",
        "#importing libraries\n",
        "!pip install timm\n",
        "import tifffile as ti\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "#load midas model from torch hub\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\")\n",
        "midas.eval()\n",
        "import cv2\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "use_large_model = True\n",
        "\n",
        "if use_large_model:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\")\n",
        "else:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\")\n",
        "  \n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if use_large_model:\n",
        "    transform = midas_transforms.default_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x8-c38310e5.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c08eeb4f662545a892edf20b3fcb125b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=356056638.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/releases/download/v2_1/model-f6b98070.pt\" to /root/.cache/torch/hub/checkpoints/model-f6b98070.pt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "713d3418dc4740fcad97b99349218917",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=422509849.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hUuPsz2NjwU"
      },
      "source": [
        "Load images from zipped **in.zip** file, run neural network and output to **out8tif.zip** (8 bit, 3 channels), **out32tif3d.zip** (32 bit, xyz channels) and **out32tif1d.zip** (32 bit, zzz channels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UytMSFJqZQuL"
      },
      "source": [
        "# unzip input folder\n",
        "!unzip in2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohlW6OSRYm_T",
        "outputId": "08cd8a81-df9b-42f3-95d2-1786bef3d978"
      },
      "source": [
        "# look for files in the input folder\n",
        "from os import walk\n",
        "_, _, filenames = next(walk('in2'))\n",
        "filenames = sorted(filenames)\n",
        "print(filenames)\n",
        "\n",
        "# create output folders for 8-bit simple output and 32-bit fully 3d vector output\n",
        "try:\n",
        "  os.makedirs('out8tif')\n",
        "except:\n",
        "  print('Folder not created')\n",
        "try:\n",
        "  os.makedirs('out32tif3d')\n",
        "except:\n",
        "  print('Folder not created')\n",
        "\n",
        "# for each filename do the depth extraction and save it\n",
        "for filename in filenames:\n",
        "  # read file\n",
        "  img = cv2.imread('in2/'+filename)\n",
        "  # convert color space from BGR to RGB\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  # run midas model\n",
        "  input_batch = transform(img).to(device)\n",
        "  with torch.no_grad():\n",
        "    prediction = midas(input_batch)\n",
        "\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "  # convert output to numpy array\n",
        "  output = prediction.cpu().numpy()\n",
        "\n",
        "  # rescale output for simple depth extraction\n",
        "  min = np.min(output)\n",
        "  max = np.max(output)\n",
        "  output2 = 255.99*(output-min)/(max-min)\n",
        "  output2 = output2.astype(int)\n",
        "  output2 = np.stack((output2,)*3, axis=-1)\n",
        "  # save simple output together with blurred versions\n",
        "  cv2.imwrite('out8tif/'+filename+'.tif', output2)\n",
        "  cv2.imwrite('out8tif/blur5'+filename+'.tif', cv2.blur(output2,(5,5)))\n",
        "  cv2.imwrite('out8tif/blur15'+filename+'.tif', cv2.blur(output2,(15,15)))\n",
        "  cv2.imwrite('out8tif/blur35'+filename+'.tif', cv2.blur(output2,(35,35)))\n",
        "\n",
        "  ## 32 bit version, mostly vector output\n",
        "  # Read shape of the depth map\n",
        "  (wy, wx) = output.shape\n",
        "\n",
        "  #distance from the camera to the image frame in arbitrary units\n",
        "  #\"hat\" suffix refers to arbitrary units \n",
        "  d1hat = wy# this is how I have choosen, but it can be changed\n",
        "  wxhat = wx\n",
        "  wyhat = wy\n",
        "\n",
        "  # rmin and rmax are two scaling factors\n",
        "  # rmin roughly means distance of the closest point visible in the image to the center of the camera\n",
        "  # rmax roughly means distance of the furthest point visible in the image to the center of the camera\n",
        "  # You can play with the values for different results.\n",
        "  # The larger is the difference between rmin and rmax, the more detailed mesh and number of bits are needed.\n",
        "  # Especially transformation from macro photography to buildings etc. may need rmin and rmax changes.\n",
        "  # rmin should rather be larger than distance from the camera to the image point.\n",
        "  rmin = 1*np.sqrt(d1hat**2+(np.max([wyhat,wxhat]))**2) #or maybe: 2*d1hat or something else :)\n",
        "  rmax = 100*rmin # or something else\n",
        "\n",
        "  # Distance from the camera. \"star\" means inverse units and rstar = a/r + b, \n",
        "  # where r is a real distance in some units and a and b are some constants that we are trying to retrieve based on rmin and rmax.\n",
        "  rstar = output\n",
        "\n",
        "  rstarmin = np.max(rstar) # max deliberately, because far points have low rstar\n",
        "  rstarmax = np.min(rstar) # min deliberately, because close points have high rstar\n",
        "\n",
        "  # Extraction of distance based on distance inverse and assumed parameters.\n",
        "  r = rmin*(rstar/(rstarmin-rstarmax) - (rstarmax/(rstarmin-rstarmax)-(rmin/rmax)*rstarmin/(rstarmin-rstarmax)))**(-1)\n",
        "\n",
        "  # Recalculation of x,y coordinates to pixel coordinates with the center in the image plane instead of top left corner.\n",
        "  xtilde = np.fromfunction(lambda i, j: j+0.5-wx/2, (wy,wx))\n",
        "  ytilde = np.fromfunction(lambda i, j: -(i+0.5-wy/2), (wy,wx))\n",
        "\n",
        "  # Distance of the point on the image plane from the camera.\n",
        "  r1 = np.sqrt(d1hat**2+xtilde**2+ytilde**2)\n",
        "\n",
        "  # Distance of the point from the image plane to the final/real position.\n",
        "  r2 = r-r1\n",
        "\n",
        "  # Transformations of the points from image plane to their final positions.\n",
        "  dx = (xtilde*r2/r1).astype(np.float32)\n",
        "  dy = (ytilde*r2/r1).astype(np.float32)\n",
        "  dz = (-d1hat*r2/r1).astype(np.float32)\n",
        "\n",
        "  # Max and min displacement ofor x,y and z.\n",
        "  allmax = np.abs(np.max(np.max([dx,dy,dz])))\n",
        "  allmin = np.abs(np.min(np.min([dx,dy,dz])))\n",
        "\n",
        "  # Max absolute displacement.\n",
        "  totmax = np.max([allmin,allmax])\n",
        "\n",
        "  # Recalculation to float 32 bit. I have assumed that 0.5 is no displacement, \n",
        "  # but it does not work as well as for 8 bit png. I do not know why, but from \n",
        "  # displacement operator point of view you just have to change midlevel.\n",
        "  dxfile = (dx/totmax/2+0.5).astype(np.float32)\n",
        "  dyfile = (dy/totmax/2+0.5).astype(np.float32)\n",
        "  dzfile = (dz/totmax/2+0.5).astype(np.float32)\n",
        "\n",
        "  # Prepare data with 3d displacement.\n",
        "  output3d = np.dstack((dxfile,dyfile,dzfile))\n",
        "  output3d = output3d.astype(np.float32)\n",
        "  # Save file with 3d displacement\n",
        "  ti.imsave('out32tif3d/'+filename+'3d.tif', output3d)\n",
        "\n",
        "# Zip the outcome folders.\n",
        "!zip out8tif.zip -r out8tif\n",
        "!zip out32tif1d.zip -r out32tif1d\n",
        "!zip out32tif3d.zip -r out32tif3d\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg']\n",
            "  adding: out8tif/ (stored 0%)\n",
            "  adding: out8tif/blur15abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg.tif (deflated 24%)\n",
            "  adding: out8tif/blur35abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg.tif (deflated 25%)\n",
            "  adding: out8tif/abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg.tif (deflated 23%)\n",
            "  adding: out8tif/blur5abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg.tif (deflated 23%)\n",
            "  adding: out32tif1d/ (stored 0%)\n",
            "  adding: out32tif3d/ (stored 0%)\n",
            "  adding: out32tif3d/abbilyn-zavgorodniaia-uOYak90r4L0-unsplash.jpg3d.tif (deflated 33%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHRhkH5lk7Yw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
